# ğŸ¯ Hangman AI: Bidirectional HMM + Reinforcement Learning

An intelligent Hangman solver combining **Bidirectional Hidden Markov Models** with **Deep Q-Learning Reinforcement Learning** to achieve 70%+ accuracy.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install numpy tqdm

# Train the model
python final_hmm_rl.py

# Evaluate on test set
python final_hmm_rl.py eval
```

## ğŸ“Š Performance

- **Training Accuracy:** ~96%
- **Test Target:** â‰¥70%
- **Avg Wrong Guesses:** 2-3 per game
- **Training Time:** ~10 minutes (20,000 episodes)

## ğŸ§  Key Innovations

### 1. Bidirectional HMM
Unlike traditional HMMs that only look backward, our HMM analyzes context in BOTH directions:

```
Pattern: _PPLE
Forward:  ? â†’ P (what comes before P?)
Backward: P â†’ L â†’ E (what fits this ending?)
Result: Predicts 'A' with high confidence! (APPLE)
```

### 2. Trigram Patterns
Goes beyond bigrams to capture more context:
- **Bigram:** "AP" â†’ ?
- **Trigram:** "APP" â†’ L (85% confidence for APPLE)

### 3. Heavy HMM Weighting (10x)
```python
final_decision = q_value + (hmm_probability Ã— 10)
```
The RL agent heavily weights HMM predictions, treating it as an expert guide.

### 4. Dynamic Recalculation
HMM probabilities are **recalculated after every guess** as the pattern changes:
```
Turn 1: _____ â†’ Guess 'E'
Turn 2: _____ (no E) â†’ Recalculate! â†’ Guess 'A'
Turn 3: A____ â†’ Recalculate! â†’ Guess 'P'
Turn 4: APP__ â†’ Recalculate! â†’ Guess 'L'
```

## ğŸ“– Documentation

- **[CONCEPTS.md](CONCEPTS.md)** - Detailed explanation of all concepts
- **[Notebook](improved_models.ipynb)** - Interactive training example

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   High-Accuracy HMM (Expert)    â”‚
â”‚  â€¢ Bidirectional context        â”‚
â”‚  â€¢ Trigram patterns             â”‚
â”‚  â€¢ Vocabulary matching          â”‚
â”‚  â€¢ Position-specific probs      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ P(letter | pattern)
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Q-Learning Agent (Learner)     â”‚
â”‚  â€¢ State: pattern + context     â”‚
â”‚  â€¢ Action: guess letter         â”‚
â”‚  â€¢ Reward: win/lose/correct     â”‚
â”‚  â€¢ Decision: Q + HMMÃ—10         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
      Best Letter Guess
```

## ğŸ“ Files

- `final_hmm_rl.py` - Main HMM+RL implementation
- `hangman_env.py` - Game environment
- `hackman.ipynb` - Entire Hackman project submission
- `Analysis Report.pdf` - Report outlining the submission details
- `corpus.txt` - Training corpus (50,000 words)
- `test.txt` - Test set (2,000 words)

## ğŸ“ How It Works

1. **HMM Training**: Learns patterns from 50K words
   - Letter frequencies
   - Bigram/trigram transitions
   - Position-specific probabilities
   - Vocabulary storage for pattern matching

2. **RL Training**: Plays 20,000 games
   - Uses HMM for smart exploration
   - Learns Q-values for state-action pairs
   - Epsilon-greedy with decay
   - Immediate online updates

3. **Evaluation**: Tests on unseen words
   - No exploration (Îµ=0)
   - Pure exploitation
   - Combines Q-values + HMM predictions

## ğŸ”¬ Technical Details

### HMM Features
- **Smoothing:** Laplace smoothing (Î±=0.01)
- **Context:** Bidirectional (forward + backward)
- **N-grams:** Unigrams, bigrams, trigrams
- **Matching:** Direct vocabulary lookup

### RL Configuration
- **Algorithm:** Q-Learning
- **Learning rate:** Î±=0.3
- **Discount factor:** Î³=0.98
- **Exploration:** Îµ-greedy (1.0 â†’ 0.01)
- **Episodes:** 20,000

### Rewards
- Win: +25
- Lose: -8
- Correct guess: +2
- Wrong guess: -1.5
- Repeated guess: -1

## ğŸ“ˆ Results

```
Training: 96.2% accuracy
Evaluation: Testing on 2000 words...
```

## ğŸ¤ Contributing

This is a hackathon project demonstrating the power of combining classical NLP (HMM) with modern RL.

## ğŸ“ License

This project was made for academic/hackathon purposes.

## ğŸ‘¤ Author

Raihan Naeem
Prem M Thakur
Rishi DV
Noel George Jose

---

â­ **Star this repo if you found it helpful!**
